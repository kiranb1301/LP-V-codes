import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# 1. Load the Fashion MNIST dataset from CSV (Assuming CSV format)
# Here, you would replace the path with the actual location of the CSV file
# We assume that the first column is the label, and the remaining 784 columns are pixel values
data = pd.read_csv('fashion_mnist_train.csv')  # Adjust this to your file path

# 2. Preprocess the Data
# Separate features (images) and labels
X = data.iloc[:, 1:].values  # All columns except the first (label)
y = data.iloc[:, 0].values  # The first column is the label

# Normalize the data to scale the pixel values to [0, 1]
X = X / 255.0

# Reshape the data to (n_samples, 28, 28, 1) to match the CNN input requirements
X = X.reshape(-1, 28, 28, 1)

# One-hot encode the labels (categories)
y = tf.keras.utils.to_categorical(y, 10)

# 3. Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 4. Define the Convolutional Neural Network (CNN) Model
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')  # Output layer for 10 classes
])

# 5. Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# 6. Train the model
history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))

# 7. Evaluate the model on the test set
test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"Test accuracy: {test_acc * 100:.2f}%")

# 8. Predict on the test data
y_pred = model.predict(X_test)

# 9. Visualize the predictions
plt.figure(figsize=(12, 8))
for i in range(10):
    plt.subplot(2, 5, i + 1)
    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')
    plt.title(f"Pred: {y_pred[i].argmax()}, True: {y_test[i].argmax()}")
    plt.axis('off')

plt.show()

# 10. Print the training and validation loss/accuracy
plt.figure(figsize=(12, 5))

# Accuracy plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Test Accuracy')
plt.title('Accuracy over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Loss plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Test Loss')
plt.title('Loss over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()
